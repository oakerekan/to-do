{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oakerekan/to-do/blob/master/OpenDeepSearch_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uITmV9KmE-Pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1342796a-d3a5-4347-bbd2-ec2914876bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OpenDeepSearch'...\n",
            "remote: Enumerating objects: 401, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 401 (delta 132), reused 127 (delta 127), pack-reused 243 (from 1)\u001b[K\n",
            "Receiving objects: 100% (401/401), 1.24 MiB | 12.12 MiB/s, done.\n",
            "Resolving deltas: 100% (211/211), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sentient-agi/OpenDeepSearch.git\n",
        "#!cd your-repo\n",
        "#!grep -R \"load_model\" -n ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/OpenDeepSearch/requirements.txt\n",
        "#you can also use: uv pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WK9orIERFjUC",
        "outputId": "c2efc446-60ea-43d8-928c-d291f68ec864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/salzubi401/crawl4ai.git@main (from -r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Cloning https://github.com/salzubi401/crawl4ai.git (to revision main) to /tmp/pip-req-build-sgym8imr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/salzubi401/crawl4ai.git /tmp/pip-req-build-sgym8imr\n",
            "  Resolved https://github.com/salzubi401/crawl4ai.git to commit 1534e64572006e1c63aab4d90e74c1d5249b5efe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai>=1.65.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/OpenDeepSearch/requirements.txt (line 1)) (1.91.0)\n",
            "Collecting datasets>=3.3.2 (from -r /content/OpenDeepSearch/requirements.txt (line 2))\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers>=4.49.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/OpenDeepSearch/requirements.txt (line 3)) (4.52.4)\n",
            "Collecting litellm>=1.61.20 (from -r /content/OpenDeepSearch/requirements.txt (line 4))\n",
            "  Downloading litellm-1.73.6-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: langchain>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from -r /content/OpenDeepSearch/requirements.txt (line 5)) (0.3.26)\n",
            "Collecting fasttext-wheel>=0.9.2 (from -r /content/OpenDeepSearch/requirements.txt (line 7))\n",
            "  Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting wikipedia-api>=0.8.1 (from -r /content/OpenDeepSearch/requirements.txt (line 8))\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/OpenDeepSearch/requirements.txt (line 9)) (11.2.1)\n",
            "Collecting smolagents>=1.9.2 (from -r /content/OpenDeepSearch/requirements.txt (line 10))\n",
            "  Downloading smolagents-1.19.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio==5.20.1 (from -r /content/OpenDeepSearch/requirements.txt (line 11))\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.115.13)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.6.0)\n",
            "Collecting gradio-client==1.7.2 (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11))\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.12.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.65.1->-r /content/OpenDeepSearch/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.65.1->-r /content/OpenDeepSearch/requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.65.1->-r /content/OpenDeepSearch/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.65.1->-r /content/OpenDeepSearch/requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (0.70.15)\n",
            "Collecting fsspec (from gradio-client==1.7.2->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11))\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r /content/OpenDeepSearch/requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r /content/OpenDeepSearch/requirements.txt (line 3)) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r /content/OpenDeepSearch/requirements.txt (line 3)) (0.5.3)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (8.2.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (8.7.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (4.24.0)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (0.9.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (0.3.66)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (2.0.41)\n",
            "Collecting aiosqlite~=0.20 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.11/dist-packages (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (5.4.0)\n",
            "Collecting playwright>=1.49.0 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading playwright-1.53.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.11/dist-packages (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (4.13.4)\n",
            "Collecting tf-playwright-stealth>=1.1.0 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading tf_playwright_stealth-1.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting rank-bm25~=0.2 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting colorama~=0.4 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting snowballstemmer~=2.2 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pyOpenSSL>=24.3.0 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading pyopenssl-25.1.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting psutil>=6.1.1 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (13.9.4)\n",
            "Collecting cssselect>=1.2.0 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fake-useragent>=2.0.3 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyperclip>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (1.9.0)\n",
            "Collecting faust-cchardet>=2.1.19 (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading faust_cchardet-2.1.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: humanize>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (4.12.3)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel>=0.9.2->-r /content/OpenDeepSearch/requirements.txt (line 7))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel>=0.9.2->-r /content/OpenDeepSearch/requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4~=4.12->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (2.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (3.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.61.20->-r /content/OpenDeepSearch/requirements.txt (line 4)) (0.25.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (0.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2025.2)\n",
            "Collecting pyee<14,>=13 (from playwright>=1.49.0->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.49.0->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: cryptography<46,>=41.0.5 in /usr/local/lib/python3.11/dist-packages (from pyOpenSSL>=24.3.0->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.3.2->-r /content/OpenDeepSearch/requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (2.19.2)\n",
            "Collecting fake-http-header<0.4.0,>=0.3.5 (from tf-playwright-stealth>=1.1.0->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6))\n",
            "  Downloading fake_http_header-0.3.5-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (1.5.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<46,>=41.0.5->pyOpenSSL>=24.3.0->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (1.17.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain>=0.3.19->-r /content/OpenDeepSearch/requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.20.1->-r /content/OpenDeepSearch/requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<46,>=41.0.5->pyOpenSSL>=24.3.0->Crawl4AI==0.5.0.post4->-r /content/OpenDeepSearch/requirements.txt (line 6)) (2.22)\n",
            "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.73.6-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smolagents-1.19.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.2/138.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faust_cchardet-2.1.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading playwright-1.53.0-py3-none-manylinux1_x86_64.whl (45.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyopenssl-25.1.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_playwright_stealth-1.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fake_http_header-0.3.5-py3-none-any.whl (14 kB)\n",
            "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: Crawl4AI, wikipedia-api\n",
            "  Building wheel for Crawl4AI (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Crawl4AI: filename=crawl4ai-0.5.0.post4-py3-none-any.whl size=252795 sha256=cd362f59b90b8c905c0c95c4430a1017f1dd6cb15a579744dec9745845c48fcc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vjl9lbfi/wheels/77/eb/27/05dd83cf2c2f440e04ccb658b7dffbee7700c70ff6b835ed94\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=22c7c1b6ebee160e90a7f84fc52aef616ae8664cacaa9b5fee85893ef65e5f3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "Successfully built Crawl4AI wikipedia-api\n",
            "Installing collected packages: snowballstemmer, faust-cchardet, rank-bm25, python-dotenv, pyee, pybind11, psutil, markupsafe, fsspec, fake-useragent, fake-http-header, cssselect, colorama, aiosqlite, aiofiles, wikipedia-api, playwright, fasttext-wheel, tf-playwright-stealth, smolagents, pyOpenSSL, gradio-client, litellm, gradio, datasets, Crawl4AI\n",
            "  Attempting uninstall: snowballstemmer\n",
            "    Found existing installation: snowballstemmer 3.0.1\n",
            "    Uninstalling snowballstemmer-3.0.1:\n",
            "      Successfully uninstalled snowballstemmer-3.0.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: pyOpenSSL\n",
            "    Found existing installation: pyOpenSSL 24.2.1\n",
            "    Uninstalling pyOpenSSL-24.2.1:\n",
            "      Successfully uninstalled pyOpenSSL-24.2.1\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.10.1\n",
            "    Uninstalling gradio_client-1.10.1:\n",
            "      Successfully uninstalled gradio_client-1.10.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.31.0\n",
            "    Uninstalling gradio-5.31.0:\n",
            "      Successfully uninstalled gradio-5.31.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Crawl4AI-0.5.0.post4 aiofiles-23.2.1 aiosqlite-0.21.0 colorama-0.4.6 cssselect-1.3.0 datasets-3.6.0 fake-http-header-0.3.5 fake-useragent-2.2.0 fasttext-wheel-0.9.2 faust-cchardet-2.1.19 fsspec-2025.3.0 gradio-5.20.1 gradio-client-1.7.2 litellm-1.73.6 markupsafe-2.1.5 playwright-1.53.0 psutil-7.0.0 pyOpenSSL-25.1.0 pybind11-2.13.6 pyee-13.0.0 python-dotenv-1.1.1 rank-bm25-0.2.2 smolagents-1.19.0 snowballstemmer-2.2.0 tf-playwright-stealth-1.2.0 wikipedia-api-0.8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "582634b174a045f3a48c639ccb358ffe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/OpenDeepSearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEUg70L0FvkM",
        "outputId": "125403ea-1345-4408-b5b1-60639aab4b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\tgradio_demo.py\tpdm.lock\tREADME.md\t  src\n",
            "evals\tLICENSE\t\tpyproject.toml\trequirements.txt  tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/OpenDeepSearch/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM1-0YQvGEpr",
        "outputId": "43919ec0-4e15-4a9d-9a95-e480d6865d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opendeepsearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/OpenDeepSearch/src')"
      ],
      "metadata": {
        "id": "8uEinqrKGIT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru\n",
        "!pip install litellm==1.65.4.post1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbDDPEn4GKpZ",
        "outputId": "be963c2b-2435-4fe5-d9c9-b09fceb6d8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n",
            "Collecting litellm==1.65.4.post1\n",
            "  Downloading litellm-1.65.4.post1.tar.gz (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (8.2.1)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (4.24.0)\n",
            "Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (1.91.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (1.1.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm==1.65.4.post1) (0.21.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.65.4.post1) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.65.4.post1) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.65.4.post1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.65.4.post1) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.65.4.post1) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.65.4.post1) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.65.4.post1) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.65.4.post1) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.65.4.post1) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.65.4.post1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.65.4.post1) (0.25.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm==1.65.4.post1) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm==1.65.4.post1) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm==1.65.4.post1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm==1.65.4.post1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm==1.65.4.post1) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm==1.65.4.post1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm==1.65.4.post1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm==1.65.4.post1) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm==1.65.4.post1) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm==1.65.4.post1) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.65.4.post1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.65.4.post1) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.65.4.post1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.65.4.post1) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.65.4.post1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.65.4.post1) (1.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.65.4.post1) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.65.4.post1) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.65.4.post1) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.65.4.post1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.65.4.post1) (6.0.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.65.4.post1) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.65.4.post1) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.65.4.post1) (2.4.0)\n",
            "Building wheels for collected packages: litellm\n",
            "  Building wheel for litellm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for litellm: filename=litellm-1.65.4.post1-py3-none-any.whl size=7076115 sha256=f0ebde92272b9a5e49c945b85bccd0790c0b9c31a951b336442b1642f675d6da\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/5a/23/45b9efe33d441fd727cd3d07a972800c73c6dd190f78a0bc28\n",
            "Successfully built litellm\n",
            "Installing collected packages: litellm\n",
            "  Attempting uninstall: litellm\n",
            "    Found existing installation: litellm 1.73.6\n",
            "    Uninstalling litellm-1.73.6:\n",
            "      Successfully uninstalled litellm-1.73.6\n",
            "Successfully installed litellm-1.65.4.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/OpenDeepSearch/.env\n",
        "OPENROUTER_API_KEY= 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\n",
        "SERPER_API_KEY= cfc4143f77ec7695f39256dd6ff661ee23e26f8c\n",
        "JINA_API_KEY=jina_c94b5a8b8382468c9bd27b3324ad9938QOUNwYktsYjhMKT9ZiWz5RN3fChn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPUp73UtGLTo",
        "outputId": "14c4af47-187e-47d4-a0b0-8ee6b396e5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/OpenDeepSearch/.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJXwQOY7i1X5",
        "outputId": "6764d2ea-8f06-4704-f460-c5a56a7a1bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m194.6/232.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libaries\n",
        "import os\n",
        "import time\n",
        "import csv\n",
        "import io\n",
        "import types\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from smolagents import CodeAgent, LiteLLMModel, Tool\n",
        "from opendeepsearch import OpenDeepSearchTool\n",
        "from PyPDF2 import PdfReader\n",
        "import litellm\n",
        "from litellm import RateLimitError, BadRequestError"
      ],
      "metadata": {
        "id": "f5lEjJZqr5M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Load environment & override base URL ─────────────────────────────────────\n",
        "load_dotenv(\"/content/OpenDeepSearch/.env\")  # loads .env from cwd\n",
        "if os.getenv(\"OPENAI_BASE_URL\"):\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
        "\n",
        "# PDF tool\n",
        "class PDFFetchTool(Tool):\n",
        "    name = \"pdf_fetch\"\n",
        "    description = \"Download a PDF from a URL and return its extracted text.\"\n",
        "    inputs = {\"url\": {\"type\": \"string\", \"description\": \"HTTP(S) URL to a PDF\"}}\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def forward(self, url: str) -> str:\n",
        "        resp = requests.get(url, timeout=30)\n",
        "        resp.raise_for_status()\n",
        "        reader = PdfReader(io.BytesIO(resp.content))\n",
        "        return \"\\n\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
        "\n",
        "#  Webpage tool\n",
        "class WebpageFetchTool(Tool):\n",
        "    name = \"visit_webpage\"\n",
        "    description = \"Fetch an HTML page and return its text content.\"\n",
        "    inputs = {\"url\": {\"type\": \"string\", \"description\": \"HTTP(S) URL to fetch\"}}\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def forward(self, url: str) -> str:\n",
        "        resp = requests.get(url, timeout=30)\n",
        "        resp.raise_for_status()\n",
        "        return resp.text\n",
        "\n",
        "# Configuration\n",
        "NAME_FILE  = \"/content/drive/MyDrive/1000Product.txt\"\n",
        "START_ID   = 1\n",
        "END_ID     = 10\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/PBR_DATA\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "#  Build search tool\n",
        "search_tool = OpenDeepSearchTool(\n",
        "    model_name=\"openrouter/meta-llama/llama-4-maverick\",\n",
        "    reranker=\"jina\",\n",
        "    search_provider=\"serper\",\n",
        "    serper_api_key=os.getenv(\"SERPER_API_KEY\", \"\")\n",
        ")\n",
        "# rename so agent will call search(...)\n",
        "search_tool.name = \"search\"\n",
        "setattr(search_tool, \"timeout\", 60)\n",
        "\n",
        "#  Instantiate the other tools\n",
        "pdf_tool      = PDFFetchTool()\n",
        "webpage_tool  = WebpageFetchTool()\n",
        "\n",
        "#  Build the orchestrator model & agent\n",
        "model = LiteLLMModel(\n",
        "    model_id=\"openrouter/meta-llama/llama-4-maverick\",\n",
        "    temperature=0.2,\n",
        "    additional_kwargs={\n",
        "        \"custom_llm_provider\": \"openrouter\",\n",
        "        \"max_tokens\": 1024,\n",
        "        \"max_completion_tokens\": 1024,\n",
        "    }\n",
        ")\n",
        "\n",
        "agent = CodeAgent(\n",
        "    tools=[search_tool, webpage_tool, pdf_tool],\n",
        "    model=model,\n",
        "    max_steps=50\n",
        ")\n",
        "setattr(agent, \"tool_timeout\", 60)\n",
        "\n",
        "# loading  product names\n",
        "def load_names(fn, lo, hi):\n",
        "    out = []\n",
        "    with open(fn, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or \".\" not in line:\n",
        "                continue\n",
        "            idx_str, name = line.split(\".\", 1)\n",
        "            try:\n",
        "                idx = int(idx_str)\n",
        "            except ValueError:\n",
        "                continue\n",
        "            if lo <= idx <= hi:\n",
        "                out.append((idx, name.strip()))\n",
        "    return out"
      ],
      "metadata": {
        "id": "OQ6loG9Et8Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6uo4WnN0BIb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Loop\n",
        "if __name__ == \"__main__\":\n",
        "    products = load_names(NAME_FILE, START_ID, END_ID)\n",
        "    if not products:\n",
        "        print(f\"No products found in {NAME_FILE} between {START_ID}-{END_ID}\")\n",
        "        exit(1)\n",
        "\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_path = os.path.join(OUTPUT_DIR, f\"output_{START_ID}_{END_ID}_{ts}.csv\")\n",
        "\n",
        "    header = [\n",
        "        \"Unstructured Product Name\",\n",
        "        \"Brand Name\",\n",
        "        \"Store Keeping Unit(SKU)\",\n",
        "        \"Active Pharmaceutical Ingredient(s)\",\n",
        "        \"Presentation\",\n",
        "        \"Company\",\n",
        "        \"Pack Type\"\n",
        "    ]\n",
        "\n",
        "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(header)\n",
        "\n",
        "        for idx, name in products:\n",
        "            prompt = f\"\"\"\n",
        "You are an AI agent with web search, webpage-fetch, and PDF parsing tools available.\n",
        "\n",
        "For the product **'{name}'**, do the following in your Python steps:\n",
        "\n",
        "1. Call **search(query=\"…\")** to find official or reliable sources online.\n",
        "2. If you find an HTML page, call **visit_webpage(url=\"…\")** to pull in the full text.\n",
        "3. If you find a PDF datasheet, call **pdf_fetch(url=\"…\")** to extract its text.\n",
        "4. Confirm dosage strength—do NOT assume numbers or units without confirmation.\n",
        "5. Extract and output these fields as one quoted, comma-separated CSV row (exactly 7 values):\n",
        "   - Unstructured Product Name\n",
        "   - Brand Name\n",
        "   - Store Keeping Unit (SKU) (dosage strength confirmed)\n",
        "   - Active Pharmaceutical Ingredient(s)\n",
        "   - Presentation\n",
        "   - Manufacturer\n",
        "   - Pack Type\n",
        "\n",
        "Return exactly one CSV row string with seven quoted values, no extras.\n",
        "\"\"\".strip()\n",
        "\n",
        "            # Retry on rate‐limit\n",
        "            while True:\n",
        "                try:\n",
        "                    row_str = agent.run(prompt).strip()\n",
        "                    break\n",
        "                except RateLimitError as e:\n",
        "                    reset = e.metadata.get(\"headers\", {}).get(\"X-RateLimit-Reset\")\n",
        "                    wait = (int(reset)/1000 - time.time()) if reset else 60\n",
        "                    wait = max(wait, 60)\n",
        "                    print(f\"⚠️  Rate limit, sleeping {int(wait)}s…\")\n",
        "                    time.sleep(wait)\n",
        "                except BadRequestError as e:\n",
        "                    print(f\"❌ Bad request: {e}\")\n",
        "                    row_str = f'\"ERROR on {idx}\"'\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Error on ID {idx}: {e}\")\n",
        "                    row_str = f'\"ERROR on {idx}\"'\n",
        "                    break\n",
        "\n",
        "            # Clean up newlines inside the AI’s CSV row\n",
        "            cleaned = row_str.replace(\"\\n\", \" \")\n",
        "\n",
        "            # Parse quoted CSV row correctly\n",
        "            try:\n",
        "                cols = next(csv.reader(\n",
        "                    io.StringIO(cleaned),\n",
        "                    quotechar='\"',\n",
        "                    skipinitialspace=True,\n",
        "                ))\n",
        "            except Exception:\n",
        "                cols = []\n",
        "\n",
        "            # Pad or truncate to exactly 7 columns\n",
        "            if len(cols) < len(header):\n",
        "                cols += [\"\"] * (len(header) - len(cols))\n",
        "            elif len(cols) > len(header):\n",
        "                cols = cols[: len(header)]\n",
        "\n",
        "            writer.writerow(cols)\n",
        "            print(f\"✅ Processed ID {idx}\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    print(f\"\\n🎉 Done – results saved to {out_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "S0zMqTrGsaQx",
        "outputId": "414f65fa-0a24-4cfb-aecc-74bea4d7d514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-502633894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Main Loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAME_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No products found in {NAME_FILE} between {START_ID}-{END_ID}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-12-778633729.py\u001b[0m in \u001b[0;36mload_names\u001b[0;34m(fn, lo, hi)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZ0qeipx105r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}